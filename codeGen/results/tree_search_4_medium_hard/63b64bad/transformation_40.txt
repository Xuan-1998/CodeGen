1. Initialize a memoization dictionary dp with default value -1 for y, where i is iteration number and y is final value of y after program termination.

2. Define function f(i) that simulates the sequence operation on state (i-1, x, y) to get the next state (x, y, i+1).

   a. If x <= 0 or x > n, terminate the program and set y as the final value.
   
   b. Increase both x and y by a_x simultaneously.
   
   c. Increase y by a_x while decreasing x by a_x.
   
   d. Return the new state (x, y, i+1).

3. Define function g(i) that runs the sequence operation on state (i-1, x, y) until termination.

   a. Initialize current_state = (i-1, 1, 0).
   
   b. Run f(current_state) until it terminates.
   
   c. Return the final value of y as the result for iteration i.

4. Main function: For each iteration i from 2 to n:
    - Call g(i) and store its return value in dp[i].

5. Print all values stored in dp dictionary as output.
